{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b7ca06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d249d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.nn import init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a27ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 超参数设置\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6791754",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "num_epochs = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f641206f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义自编码器模型\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(199, 140),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(140, 80),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(80, 20)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(20, 80),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(80, 140),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(140, 199)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return encoded, decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6389bb12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tain_epoch(train_dataloader, autoencoder, criterion, autoencoder_optimizer):\n",
    "    autoencoder.train()\n",
    "    total_loss = 0.0\n",
    "    num_batches = len(train_dataloader)\n",
    "    for train_dataloader1 in train_dataloader:\n",
    "        autoencoder_optimizer.zero_grad()\n",
    "        _, decoded = autoencoder(train_dataloader1)\n",
    "        autoencoder_loss = criterion(decoded, train_dataloader1)\n",
    "        autoencoder_loss.backward()\n",
    "        autoencoder_optimizer.step()\n",
    "        total_loss += autoencoder_loss.item()\n",
    "    average_loss = total_loss/num_batches\n",
    "    return average_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdccc3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_epoch(test_dataloader, autoencoder, criterion):\n",
    "    autoencoder.eval()\n",
    "    total_loss = 0.0\n",
    "    num_batches = len(test_dataloader)\n",
    "\n",
    "    for test_dataloader1 in test_dataloader:\n",
    "        _, decoded = autoencoder(test_dataloader1)\n",
    "        autoencoder_loss = criterion(decoded, test_dataloader1)\n",
    "        total_loss += autoencoder_loss.item()\n",
    "    average_loss = total_loss / num_batches\n",
    "    return average_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67732d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_train():\n",
    "    # 创建自编码器和MLP模型\n",
    "    autoencoder = Autoencoder()\n",
    "    autoencoder = autoencoder.cuda()\n",
    "\n",
    "    # 定义损失函数和优化器\n",
    "    criterion = nn.MSELoss()  # 均方误差损失\n",
    "    criterion = criterion.cuda()\n",
    "    autoencoder_optimizer = optim.Adam(autoencoder.parameters(), lr=learning_rate)\n",
    "\n",
    "    # 加载数据\n",
    "    data = np.loadtxt('airfoils_recon_data.dat')[:, 204:]\n",
    "    # 压力系数归一化\n",
    "    min = np.min(data, axis=0)\n",
    "    max = np.max(data, axis=0)\n",
    "    data_nom = (data - min) / (max - min)\n",
    "\n",
    "    data_nom_tensor = torch.tensor(data_nom, dtype=torch.float32)\n",
    "    train_data, test_data = train_test_split(data_nom_tensor, test_size=0.1, random_state=42)\n",
    "    train_data = train_data.cuda()\n",
    "    test_data = test_data.cuda()\n",
    "    train_dataloader = DataLoader(train_data, batch_size=512, shuffle=True)\n",
    "    test_dataloader = DataLoader(test_data, batch_size=512, shuffle=True)\n",
    "\n",
    "    # 自编码器训练\n",
    "    AE_train_loss = []\n",
    "    AE_test_loss = []\n",
    "    coe = np.arange(0.1, 1, 0.2)\n",
    "    for epoch in range(num_epochs):\n",
    "        if epoch in num_epochs * coe:\n",
    "            for param_group in autoencoder_optimizer.param_groups:\n",
    "                param_group['lr'] *= 0.5\n",
    "\n",
    "        train_loss = tain_epoch(train_dataloader, autoencoder, criterion, autoencoder_optimizer)\n",
    "        AE_train_loss.append(train_loss)\n",
    "        test_loss = test_epoch(test_dataloader, autoencoder, criterion)\n",
    "        AE_test_loss.append(test_loss)\n",
    "\n",
    "        if (epoch+1) % 1 == 0:\n",
    "            print(f'MLP训练 Epoch [{epoch + 1}/{num_epochs}], MLP_train_loss: {AE_train_loss[-1]}, '\n",
    "                  f'MLP_test_loss:{AE_test_loss[-1]}')\n",
    "\n",
    "    torch.save(autoencoder, 'autoencoder20.pkl')\n",
    "    np.savetxt('cpAE_train_loss20.dat', AE_train_loss, delimiter='\\t')\n",
    "    np.savetxt('cpAE_test_loss20.dat', AE_test_loss, delimiter='\\t')\n",
    "\n",
    "    # 自编码器loss图\n",
    "    plt.Figure()\n",
    "    plt.title('autoencoder MSE loss')\n",
    "    plt.xlabel('epochs')\n",
    "    plt.semilogy(np.arange(num_epochs), AE_train_loss, linewidth=0.5, color='blue', label='train')\n",
    "    plt.semilogy(np.arange(num_epochs), AE_test_loss, linewidth=0.5, color='red', label='test')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # # 自编码器验证\n",
    "    # encoded, decoded = autoencoder(val_data)\n",
    "    # autoencoder_MSE = criterion(decoded, val_data)\n",
    "    # print(f'autoencoder_MSE = {autoencoder_MSE}')\n",
    "    # loc_x = np.loadtxt('loc_x.dat')\n",
    "    # plt.Figure()\n",
    "    # plt.title('val_autoencoder')\n",
    "    # plt.scatter(loc_x, val_data[1, :].detach().numpy(), s=2, color='blue')\n",
    "    # plt.plot(loc_x, decoded[1, :].detach().numpy(), linewidth=1, color='red')\n",
    "    # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc3cacc",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "    main_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c8da40",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
