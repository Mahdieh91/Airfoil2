To make the results showable on Colab when calling this notebook from GitHub, we need to ensure that:

1. All outputs (plots, print statements) are properly displayed
2. The notebook can run in a Colab environment without manual intervention
3. The data loading works correctly (either from GitHub or by uploading to Colab)

Here's the modified version that maintains the same functionality but ensures results are visible when run on Colab:

```python
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github"
   },
   "source": [
    "# Airfoil VAE: Training and Generation\n",
    "\n",
    "This notebook handles the complete pipeline for:\n",
    "1. Training a Variational Autoencoder (VAE) on airfoil data with cosine noise\n",
    "2. Generating new airfoil designs from the trained model\n",
    "3. Evaluating the generated airfoils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0QKt5zRq2bQH"
   },
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1JzJcVgX2bQI"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from scipy.signal import savgol_filter\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from google.colab import output\n",
    "\n",
    "# Enable inline plotting\n",
    "%matplotlib inline\n",
    "\n",
    "# Verify GPU availability\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Setup directory (for Colab)\n",
    "if 'COLAB_GPU' in os.environ:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    os.chdir('/content/drive/MyDrive/Airfoil2/m1_airfoilvae/ActFun_relu')  # Update with your path\n",
    "    print(\"Current directory:\", os.getcwd())\n",
    "    !ls\n",
    "    \n",
    "# Clear any existing output\n",
    "output.clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hQ5gQJ4s2bQK"
   },
   "source": [
    "## 2. Cosine Noise Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0JY2Q9xS2bQK"
   },
   "outputs": [],
   "source": [
    "def generate_cosine_noise(num_samples, length, amplitude=1e-5, frequency=10):\n",
    "    \"\"\"Generate structured cosine noise for airfoil data\"\"\"\n",
    "    x = np.linspace(0, 2*np.pi, length)\n",
    "    noise = np.zeros((num_samples, length))\n",
    "    for i in range(num_samples):\n",
    "        phase_shift = np.random.uniform(0, 2*np.pi)\n",
    "        freq_variation = np.random.uniform(0.8, 1.2) * frequency\n",
    "        noise[i] = amplitude * np.cos(freq_variation * x + phase_shift)\n",
    "    return noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7V5qQ5LZ2bQL"
   },
   "source": [
    "## 3. Data Loading and Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7Tj3fJ2v2bQL"
   },
   "outputs": [],
   "source": [
    "# For Colab users - download data if not present\n",
    "if 'COLAB_GPU' in os.environ and not os.path.exists('airfoils.dat'):\n",
    "    !wget https://raw.githubusercontent.com/your_username/your_repo/main/airfoils.dat\n",
    "\n",
    "# Verify data file exists\n",
    "assert os.path.exists('airfoils.dat'), \"airfoils.dat not found in current directory\"\n",
    "\n",
    "# Load and prepare data with noise\n",
    "data = np.loadtxt('airfoils.dat')\n",
    "data = data[:, 1:]  # Remove first column if needed\n",
    "\n",
    "# Generate and add noise\n",
    "noise = generate_cosine_noise(data.shape[0], data.shape[1], amplitude=1e-5)\n",
    "data_with_noise = data + noise\n",
    "\n",
    "# Normalize data\n",
    "data_min = np.min(data_with_noise, axis=0)\n",
    "data_max = np.max(data_with_noise, axis=0)\n",
    "data_norm = (data_with_noise - data_min) / (data_max - data_min)\n",
    "data_tensor = torch.tensor(data_norm, dtype=torch.float32).to(device)\n",
    "\n",
    "print(f\"Data loaded successfully. Shape: {data_tensor.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H3c1sYlq2bQM"
   },
   "source": [
    "## 4. VAE Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7P3V4g1I2bQM"
   },
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_sizes, latent_dim, activation_function='relu'):\n",
    "        super(VAE, self).__init__()\n",
    "        self.activation_function = activation_function\n",
    "\n",
    "        # Encoder\n",
    "        self.encoders = nn.ModuleList()\n",
    "        in_dim = input_dim\n",
    "        for h_dim in hidden_sizes:\n",
    "            self.encoders.append(nn.Linear(in_dim, h_dim))\n",
    "            in_dim = h_dim\n",
    "\n",
    "        self.fc_mu = nn.Linear(hidden_sizes[-1], latent_dim)\n",
    "        self.fc_logvar = nn.Linear(hidden_sizes[-1], latent_dim)\n",
    "\n",
    "        # Decoder\n",
    "        self.decoders = nn.ModuleList()\n",
    "        in_dim = latent_dim\n",
    "        for h_dim in reversed(hidden_sizes):\n",
    "            self.decoders.append(nn.Linear(in_dim, h_dim))\n",
    "            in_dim = h_dim\n",
    "\n",
    "        self.fc_out = nn.Linear(hidden_sizes[0], input_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encoder(x)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        return self.decoder(z), mu, logvar\n",
    "    \n",
    "    def encoder(self, x):\n",
    "        for layer in self.encoders:\n",
    "            x = layer(x)\n",
    "            x = self._apply_activation(x)\n",
    "        return self.fc_mu(x), self.fc_logvar(x)\n",
    "    \n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "    \n",
    "    def decoder(self, z):\n",
    "        for layer in self.decoders:\n",
    "            z = layer(z)\n",
    "            z = self._apply_activation(z)\n",
    "        return self.fc_out(z)\n",
    "    \n",
    "    def _apply_activation(self, x):\n",
    "        if self.activation_function == 'relu':\n",
    "            return F.relu(x)\n",
    "        elif self.activation_function == 'tanh':\n",
    "            return torch.tanh(x)\n",
    "        elif self.activation_function == 'leaky_relu':\n",
    "            return F.leaky_relu(x)\n",
    "        elif self.activation_function == 'sigmoid':\n",
    "            return torch.sigmoid(x)\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported activation: {self.activation_function}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w1s9H8b62bQN"
   },
   "source": [
    "## 5. Training Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qc1kfXe62bQN"
   },
   "outputs": [],
   "source": [
    "def train_vae(data_tensor, input_dim, device, params):\n",
    "    \"\"\"Complete training procedure\"\"\"\n",
    "    model = VAE(\n",
    "        input_dim=input_dim,\n",
    "        hidden_sizes=params['hidden_sizes'],\n",
    "        latent_dim=params['latent_dim'],\n",
    "        activation_function=params['activation']\n",
    "    ).to(device)\n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters(), lr=params['lr'])\n",
    "    \n",
    "    train_losses = []\n",
    "    model.train()\n",
    "    \n",
    "    for epoch in range(params['epochs']):\n",
    "        optimizer.zero_grad()\n",
    "        recon, mu, logvar = model(data_tensor)\n",
    "        \n",
    "        # Reconstruction + KL divergence losses\n",
    "        mse_loss = F.mse_loss(recon, data_tensor, reduction='sum')\n",
    "        kld_loss = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "        loss = mse_loss + kld_loss\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_losses.append(loss.item())\n",
    "        \n",
    "        if (epoch + 1) % 500 == 0:\n",
    "            print(f\"Epoch {epoch+1}/{params['epochs']}, Loss: {loss.item():.4f}\")\n",
    "    \n",
    "    return model, train_losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8jYl7w1P2bQO"
   },
   "source": [
    "## 6. Training Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S1p0RkU22bQO"
   },
   "outputs": [],
   "source": [
    "# Configuration\n",
    "params = {\n",
    "    'hidden_sizes': [200, 150, 100],\n",
    "    'latent_dim': 8,\n",
    "    'activation': 'relu',\n",
    "    'lr': 0.001,\n",
    "    'epochs': 5000\n",
    "}\n",
    "\n",
    "# Train the model\n",
    "print(\"Starting training...\")\n",
    "trained_model, losses = train_vae(\n",
    "    data_tensor=data_tensor,\n",
    "    input_dim=data_tensor.shape[1],\n",
    "    device=device,\n",
    "    params=params\n",
    ")\n",
    "\n",
    "# Save the trained model\n",
    "torch.save(trained_model.state_dict(), 'best_vae.pth')\n",
    "print(\"Training completed and model saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hQ4N6m1w2bQP"
   },
   "source": [
    "## 7. Training Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l5Q1nNqY2bQP"
   },
   "outputs": [],
   "source": [
    "# Plot training loss\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(losses)\n",
    "plt.title('Training Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Also print final loss values\n",
    "print(f\"Initial loss: {losses[0]:.2f}\")\n",
    "print(f\"Final loss: {losses[-1]:.2f}\")\n",
    "print(f\"Minimum loss: {min(losses):.2f} at epoch {losses.index(min(losses))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t1Qa5J8F2bQQ"
   },
   "source": [
    "## 8. Airfoil Generation and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d9J0Z4Q62bQQ"
   },
   "outputs": [],
   "source": [
    "# Load trained model\n",
    "best_params = ([200, 150, 100], 0.001, 8, 'relu')\n",
    "hidden_sizes, learning_rate, latent_dim, activation_function = best_params\n",
    "\n",
    "vae = VAE(\n",
    "    input_dim=data_tensor.shape[1],\n",
    "    hidden_sizes=hidden_sizes,\n",
    "    latent_dim=latent_dim,\n",
    "    activation_function=activation_function\n",
    ").to(device)\n",
    "\n",
    "vae.load_state_dict(torch.load('best_vae.pth'))\n",
    "vae.eval()\n",
    "\n",
    "print(\"Model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XJjfF8Q02bQR"
   },
   "outputs": [],
   "source": [
    "# Generate new airfoils\n",
    "print(\"Generating airfoils...\")\n",
    "airfoils_recon = []\n",
    "for j in range(1000):\n",
    "    sample_mu = np.random.normal(loc=0, scale=1.2, size=(len(data), latent_dim))\n",
    "    sample_mu = torch.tensor(sample_mu, dtype=torch.float32).to(device)\n",
    "    recon = vae.decoder(sample_mu)\n",
    "    if len(airfoils_recon) == 0:\n",
    "        airfoils_recon = recon.detach().cpu().numpy()\n",
    "    else:\n",
    "        airfoils_recon = np.vstack((airfoils_recon, recon.detach().cpu().numpy()))\n",
    "        \n",
    "# Denormalize\n",
    "airfoils_recon = airfoils_recon * (data_max - data_min) + data_min\n",
    "print(f\"Generated {len(airfoils_recon)} airfoils\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c9J0Z4Q62bQR"
   },
   "outputs": [],
   "source": [
    "# Evaluate generated airfoils\n",
    "VAE_diversity = np.mean(np.var(airfoils_recon, axis=0))\n",
    "airfoil_filter = np.apply_along_axis(lambda x: savgol_filter(x, 15,
