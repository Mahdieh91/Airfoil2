{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Airfoil VAE: Training and Generation\n",
    "\n",
    "This notebook handles the complete pipeline for:\n",
    "1. Training a Variational Autoencoder (VAE) on airfoil data with cosine noise\n",
    "2. Generating new airfoil designs from the trained model\n",
    "3. Evaluating the generated airfoils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from scipy.signal import savgol_filter\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# Verify GPU availability\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Setup directory (for Colab)\n",
    "if 'COLAB_GPU' in os.environ:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    os.chdir('/content/drive/MyDrive/Airfoil2/m1_airfoilvae/ActFun_relu')  # Update with your path\n",
    "    print(\"Current directory:\", os.getcwd())\n",
    "    !ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Cosine Noise Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_cosine_noise(num_samples, length, amplitude=1e-5, frequency=10):\n",
    "    \"\"\"Generate structured cosine noise for airfoil data\"\"\"\n",
    "    x = np.linspace(0, 2*np.pi, length)\n",
    "    noise = np.zeros((num_samples, length))\n",
    "    for i in range(num_samples):\n",
    "        phase_shift = np.random.uniform(0, 2*np.pi)\n",
    "        freq_variation = np.random.uniform(0.8, 1.2) * frequency\n",
    "        noise[i] = amplitude * np.cos(freq_variation * x + phase_shift)\n",
    "    return noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Loading and Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify data file exists\n",
    "assert os.path.exists('airfoils.dat'), \"airfoils.dat not found in current directory\"\n",
    "\n",
    "# Load and prepare data with noise\n",
    "data = np.loadtxt('airfoils.dat')\n",
    "data = data[:, 1:]  # Remove first column if needed\n",
    "\n",
    "# Generate and add noise\n",
    "noise = generate_cosine_noise(data.shape[0], data.shape[1], amplitude=1e-5)\n",
    "data_with_noise = data + noise\n",
    "\n",
    "# Normalize data\n",
    "data_min = np.min(data_with_noise, axis=0)\n",
    "data_max = np.max(data_with_noise, axis=0)\n",
    "data_norm = (data_with_noise - data_min) / (data_max - data_min)\n",
    "data_tensor = torch.tensor(data_norm, dtype=torch.float32).to(device)\n",
    "\n",
    "print(f\"Data loaded successfully. Shape: {data_tensor.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. VAE Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_sizes, latent_dim, activation_function='relu'):\n",
    "        super(VAE, self).__init__()\n",
    "        self.activation_function = activation_function\n",
    "\n",
    "        # Encoder\n",
    "        self.encoders = nn.ModuleList()\n",
    "        in_dim = input_dim\n",
    "        for h_dim in hidden_sizes:\n",
    "            self.encoders.append(nn.Linear(in_dim, h_dim))\n",
    "            in_dim = h_dim\n",
    "\n",
    "        self.fc_mu = nn.Linear(hidden_sizes[-1], latent_dim)\n",
    "        self.fc_logvar = nn.Linear(hidden_sizes[-1], latent_dim)\n",
    "\n",
    "        # Decoder\n",
    "        self.decoders = nn.ModuleList()\n",
    "        in_dim = latent_dim\n",
    "        for h_dim in reversed(hidden_sizes):\n",
    "            self.decoders.append(nn.Linear(in_dim, h_dim))\n",
    "            in_dim = h_dim\n",
    "\n",
    "        self.fc_out = nn.Linear(hidden_sizes[0], input_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encoder(x)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        return self.decoder(z), mu, logvar\n",
    "    \n",
    "    def encoder(self, x):\n",
    "        for layer in self.encoders:\n",
    "            x = layer(x)\n",
    "            x = self._apply_activation(x)\n",
    "        return self.fc_mu(x), self.fc_logvar(x)\n",
    "    \n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "    \n",
    "    def decoder(self, z):\n",
    "        for layer in self.decoders:\n",
    "            z = layer(z)\n",
    "            z = self._apply_activation(z)\n",
    "        return self.fc_out(z)\n",
    "    \n",
    "    def _apply_activation(self, x):\n",
    "        if self.activation_function == 'relu':\n",
    "            return F.relu(x)\n",
    "        elif self.activation_function == 'tanh':\n",
    "            return torch.tanh(x)\n",
    "        elif self.activation_function == 'leaky_relu':\n",
    "            return F.leaky_relu(x)\n",
    "        elif self.activation_function == 'sigmoid':\n",
    "            return torch.sigmoid(x)\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported activation: {self.activation_function}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Training Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_vae(data_tensor, input_dim, device, params):\n",
    "    \"\"\"Complete training procedure\"\"\"\n",
    "    model = VAE(\n",
    "        input_dim=input_dim,\n",
    "        hidden_sizes=params['hidden_sizes'],\n",
    "        latent_dim=params['latent_dim'],\n",
    "        activation_function=params['activation']\n",
    "    ).to(device)\n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters(), lr=params['lr'])\n",
    "    \n",
    "    train_losses = []\n",
    "    model.train()\n",
    "    \n",
    "    for epoch in range(params['epochs']):\n",
    "        optimizer.zero_grad()\n",
    "        recon, mu, logvar = model(data_tensor)\n",
    "        \n",
    "        # Reconstruction + KL divergence losses\n",
    "        mse_loss = F.mse_loss(recon, data_tensor, reduction='sum')\n",
    "        kld_loss = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "        loss = mse_loss + kld_loss\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_losses.append(loss.item())\n",
    "        \n",
    "        if (epoch + 1) % 500 == 0:\n",
    "            print(f\"Epoch {epoch+1}/{params['epochs']}, Loss: {loss.item():.4f}\")\n",
    "    \n",
    "    return model, train_losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Training Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "params = {\n",
    "    'hidden_sizes': [200, 150, 100],\n",
    "    'latent_dim': 8,\n",
    "    'activation': 'relu',\n",
    "    'lr': 0.001,\n",
    "    'epochs': 5000\n",
    "}\n",
    "\n",
    "# Train the model\n",
    "trained_model, losses = train_vae(\n",
    "    data_tensor=data_tensor,\n",
    "    input_dim=data_tensor.shape[1],\n",
    "    device=device,\n",
    "    params=params\n",
    ")\n",
    "\n",
    "# Save the trained model\n",
    "torch.save(trained_model.state_dict(), 'best_vae.pth')\n",
    "print(\"Training completed and model saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Training Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training loss\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(losses)\n",
    "plt.title('Training Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Airfoil Generation and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load trained model\n",
    "best_params = ([200, 150, 100], 0.001, 8, 'relu')\n",
    "hidden_sizes, learning_rate, latent_dim, activation_function = best_params\n",
    "\n",
    "vae = VAE(\n",
    "    input_dim=data_tensor.shape[1],\n",
    "    hidden_sizes=hidden_sizes,\n",
    "    latent_dim=latent_dim,\n",
    "    activation_function=activation_function\n",
    ").to(device)\n",
    "\n",
    "vae.load_state_dict(torch.load('best_vae.pth'))\n",
    "vae.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate new airfoils\n",
    "airfoils_recon = []\n",
    "for j in range(1000):\n",
    "    sample_mu = np.random.normal(loc=0, scale=1.2, size=(len(data), latent_dim))\n",
    "    sample_mu = torch.tensor(sample_mu, dtype=torch.float32).to(device)\n",
    "    recon = vae.decoder(sample_mu)\n",
    "    if len(airfoils_recon) == 0:\n",
    "        airfoils_recon = recon.detach().cpu().numpy()\n",
    "    else:\n",
    "        airfoils_recon = np.vstack((airfoils_recon, recon.detach().cpu().numpy()))\n",
    "        \n",
    "# Denormalize\n",
    "airfoils_recon = airfoils_recon * (data_max - data_min) + data_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate generated airfoils\n",
    "VAE_diversity = np.mean(np.var(airfoils_recon, axis=0))\n",
    "airfoil_filter = np.apply_along_axis(lambda x: savgol_filter(x, 15, 3), axis=1, arr=airfoils_recon)\n",
    "VAE_roughness = np.mean(np.mean((airfoils_recon - airfoil_filter) ** 2, axis=1))\n",
    "\n",
    "print(\"=== Generation Results ===\")\n",
    "print(f\"Relative Diversity: {VAE_diversity/0.00038256164690759424:.4f}\")\n",
    "print(f\"Relative Roughness: {VAE_roughness/2.9165800679528876e-09:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Sample Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot some generated airfoils\n",
    "plt.figure(figsize=(10, 6))\n",
    "for i in range(5):\n",
    "    plt.plot(airfoils_recon[i], label=f'Generated Airfoil {i+1}')\n",
    "plt.title('Sample Generated Airfoils')\n",
    "plt.xlabel('Position')\n",
    "plt.ylabel('Value')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}